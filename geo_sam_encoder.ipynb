{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.datasets import unbind_samples, stack_samples, BoundingBox, IntersectionDataset, RasterDataset\n",
    "from torchgeo.samplers import Units, GridGeoSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.torchgeo_sam import SamTestGridGeoSampler, SamTestRasterDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rescale_img(batch_input: Tensor, range_max: float, range_min: float) -> Tensor:\n",
    "    'rescale input image to [0,255]'\n",
    "    batch_output = (batch_input - range_min)*255/(range_max - range_min)\n",
    "    return batch_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B1', 'B2', 'B3'], ['B1', 'B2', 'B3'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_max = 255\n",
    "range_min = 0\n",
    "band_count = 3\n",
    "selected_bands = [1, 2, 3]\n",
    "# selected_bands = [1]\n",
    "all_bands = [\n",
    "    f'B{i_band}' for i_band in range(1, band_count+1)\n",
    "]\n",
    "SamTestRasterDataset.all_bands = all_bands\n",
    "input_bands = [all_bands[i_band-1] for i_band in selected_bands]\n",
    "if len(input_bands) < 3:\n",
    "    input_bands = (input_bands * 3)[0:3]\n",
    "SamTestRasterDataset.filename_glob = '*rgb_8bit.tif'\n",
    "all_bands, input_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raster num:  4\n",
      "['B1', 'B2', 'B3']\n",
      "['B1', 'B2', 'B3']\n",
      "EPSG:32646\n",
      "3.1249999999999996\n"
     ]
    }
   ],
   "source": [
    "raster_dir = \"\"\n",
    "test_imgs = SamTestRasterDataset(root=raster_dir, crs=None, bands=input_bands, cache=False) #\n",
    "print('raster num: ', test_imgs.index.get_size())\n",
    "print(test_imgs.all_bands)\n",
    "print(test_imgs.bands)\n",
    "print(test_imgs.crs)\n",
    "print(test_imgs.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "mint: float = 0\n",
    "maxt: float = sys.maxsize\n",
    "# process_extent = 522758.25605501, 722743.76583600, 7347229.60405119, 7500227.52738657\n",
    "# ROI = BoundingBox(*process_extent, mint, maxt)\n",
    "ROI = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5320"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source images should be larger than 1024 * 1024\n",
    "test_sampler = SamTestGridGeoSampler(test_imgs, size=1024, stride=512, roi=ROI, units=Units.PIXELS) # Units.CRS or Units.PIXELS\n",
    "len(test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "i_jump = np.random.randint(len(test_sampler)-5)\n",
    "for query in test_sampler:\n",
    "    i = i+1\n",
    "    if i>i_jump:\n",
    "        sample = test_imgs[query]\n",
    "        display(sample.keys())\n",
    "        print(sample['path'])\n",
    "        print(sample['image'].shape)\n",
    "        print(sample['image'].max(), sample['image'].max())\n",
    "        rds_img = rescale_img(sample['image'], range_max, range_min)\n",
    "        print(rds_img.max(), rds_img.min())\n",
    "        raster_img = np.transpose(rds_img.numpy(), (1, 2 ,0))\n",
    "        print(raster_img.shape)\n",
    "        plt.imshow(raster_img.astype(np.uint8))\n",
    "        plt.show()\n",
    "    if i > i_jump+5:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_imgs, batch_size=16, sampler=test_sampler, collate_fn=stack_samples) # \n",
    "\n",
    "for batch in test_dataloader:\n",
    "    print(batch.keys())\n",
    "    print(batch['image'].shape)\n",
    "    display(batch['path'])\n",
    "    # display(batch['bbox'])\n",
    "    display(len(batch['image']))\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize sam predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sam_checkpoint = \"../sam_dev/checkpoint/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "cuda_id = 0\n",
    "\n",
    "sam_model = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "if torch.cuda.is_available():\n",
    "    if cuda_id + 1 > torch.cuda.device_count():\n",
    "        cuda_id = torch.cuda.device_count() - 1\n",
    "    cuda_device = f'cuda:{cuda_id}'\n",
    "    sam_model.to(device=cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_sam_feature(model, batch_input) -> np.ndarray:\n",
    "    batch_input = batch_input.to(device=sam_model.device)\n",
    "    batch_input = (batch_input - model.pixel_mean) / model.pixel_std\n",
    "    features = model.image_encoder(batch_input)\n",
    "    return features.cpu().numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features and save as tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sam_feature(\n",
    "    raster_ds: SamTestRasterDataset,\n",
    "    export_dir: Path,\n",
    "    data_batch: Tensor,\n",
    "    feature: np.ndarray,\n",
    "    extent: BoundingBox,\n",
    "    patch_count: int,\n",
    "    model_type: str = \"vit_h\"\n",
    ") -> int:\n",
    "    # iterate over batch_size dimension\n",
    "    for idx in range(feature.shape[-4]):\n",
    "        band_num = feature.shape[-3]\n",
    "        height = feature.shape[-2]\n",
    "        width = feature.shape[-1]\n",
    "        bbox = data_batch['bbox'][idx]\n",
    "        rio_transform = rasterio.transform.from_bounds(\n",
    "            bbox.minx, bbox.miny, bbox.maxx, bbox.maxy, width, height)  # west, south, east, north, width, height\n",
    "        filepath = Path(data_batch['path'][idx])\n",
    "        bbox_list = [bbox.minx, bbox.miny, bbox.maxx, bbox.maxy]\n",
    "        bbox_str = '_'.join(map(\"{:.6f}\".format, bbox_list))\n",
    "        extent_list = [extent.minx, extent.miny, extent.maxx, extent.maxy]\n",
    "        extent_str = '_'.join(\n",
    "            map(\"{:.6f}\".format, extent_list)) + f\"_res_{raster_ds.res:.6f}\"\n",
    "        #  Unicode-objects must be encoded before hashing with hashlib and\n",
    "        #  because strings in Python 3 are Unicode by default (unlike Python 2),\n",
    "        #  you'll need to encode the string using the .encode method.\n",
    "        bbox_hash = hashlib.sha256(bbox_str.encode(\"utf-8\")).hexdigest()\n",
    "        extent_hash = hashlib.sha256(\n",
    "            extent_str.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "        bands_str = '_'.join([str(band) for band in raster_ds.band_indexes])\n",
    "        export_dir_sub = (export_dir / filepath.stem /\n",
    "                            f\"sam_feat_{model_type}_bands_{bands_str}_{extent_hash[0:16]}\")\n",
    "        export_dir_sub.mkdir(parents=True, exist_ok=True)\n",
    "        feature_tiff = (export_dir_sub /\n",
    "                        f\"sam_feat_{model_type}_{bbox_hash}.tif\")\n",
    "        feature_csv = (export_dir_sub / f\"{export_dir_sub.name}.csv\")\n",
    "        with rasterio.open(\n",
    "                feature_tiff,\n",
    "                mode=\"w\",\n",
    "                driver=\"GTiff\",\n",
    "                height=height, width=width,\n",
    "                count=band_num,\n",
    "                dtype='float32',\n",
    "                crs=data_batch['crs'][idx],\n",
    "                transform=rio_transform\n",
    "        ) as feature_dataset:\n",
    "            # index start from 1, feature[idx, :, :, :] = feature[idx, ...], later is faster\n",
    "            feature_dataset.write(feature[idx, ...], range(1, band_num+1))\n",
    "            # pr_mask_dataset.set_band_description(1, '')\n",
    "            tags = {\n",
    "                \"img_shape\": data_batch[\"img_shape\"][idx],\n",
    "                \"input_shape\": data_batch[\"input_shape\"][idx],\n",
    "                \"model_type\": model_type,\n",
    "            }\n",
    "            feature_dataset.update_tags(**tags)\n",
    "            feature_res = feature_dataset.res[0]\n",
    "            feature_crs = feature_dataset.crs\n",
    "\n",
    "        index_df = pd.DataFrame(columns=['minx', 'maxx', 'miny', 'maxy', 'mint', 'maxt',\n",
    "                                            'filepath',\n",
    "                                            'crs', 'res'],\n",
    "                                index=[patch_count])\n",
    "        index_df['filepath'] = [feature_tiff.name]\n",
    "        index_df['minx'] = [bbox.minx]\n",
    "        index_df['maxx'] = [bbox.maxx]\n",
    "        index_df['miny'] = [bbox.miny]\n",
    "        index_df['maxy'] = [bbox.maxy]\n",
    "        index_df['mint'] = [bbox.mint]\n",
    "        index_df['maxt'] = [bbox.maxt]\n",
    "        index_df['crs'] = [str(feature_crs)]\n",
    "        index_df['res'] = [raster_ds.res]\n",
    "        index_df['model_type'] = [model_type]\n",
    "        # append data frame to CSV file, index=False\n",
    "        index_df.to_csv(feature_csv, mode='a',\n",
    "                        header=not feature_csv.exists(), index=True)\n",
    "        patch_count += 1\n",
    "\n",
    "    return patch_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [23:15<00:00,  8.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "export_dir = Path('/DATA/DATA2/joey/sam_data/features/')\n",
    "patch_count = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # print(batch.keys())\n",
    "    # print(batch['image'].shape)\n",
    "    # display(batch['path'])\n",
    "    # display(batch['bbox'])\n",
    "    # display(batch_input.shape)\n",
    "    batch_input = rescale_img(batch_input=batch['image'], range_max=range_max, range_min=range_min)\n",
    "    features = get_sam_feature(sam_model, batch_input)\n",
    "    # display(features.shape)\n",
    "    patch_count = save_sam_feature(test_imgs, export_dir, batch, features, ROI, patch_count, model_type='vit_h')\n",
    "\n",
    "    # break\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
